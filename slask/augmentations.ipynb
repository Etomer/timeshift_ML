{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import scipy.io.wavfile as wav\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torchaudio\n",
    "import glob\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from bisect import bisect_left\n",
    "import scipy as sp\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"../datasets/generated_dataset/\"\n",
    "device = 'cuda' if torch.cuda.is_available() else ('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "dropout = 0.1\n",
    "batch_size = 128\n",
    "fs = 16000\n",
    "\n",
    "max_shift = 500 # in samples\n",
    "guess_grid_size = max_shift\n",
    "\n",
    "\n",
    "f = h5py.File(\"../datasets/generated_dataset/generated_dataset.hdf5\",\"r\")\n",
    "\n",
    "\n",
    "X = f['input']\n",
    "y = f['gt']\n",
    "\n",
    "f_test = h5py.File(\"../datasets/generated_dataset/generated_dataset_valer.hdf5\",\"r\")\n",
    "X_test = f_test['input']\n",
    "y_test = f_test['gt']\n",
    "\n",
    "#X = torch.load(os.path.join(data_folder,\"input2.pt\"))\n",
    "#y = torch.load(os.path.join(data_folder,\"gt2.pt\"))\n",
    "#X_test = torch.load(os.path.join(data_folder,\"input.pt\"))\n",
    "#y_test = torch.load(os.path.join(data_folder,\"gt.pt\"))\n",
    "\n",
    "class custom_dataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, y, idx_min=0,dataset_len=len(X)):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.dataset_len = dataset_len\n",
    "        self.idx_min = idx_min\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx + self.idx_min],self.y[idx + self.idx_min]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_len\n",
    "\n",
    "split_i = int(X.shape[0]*0.98)\n",
    "dataset = custom_dataset(X,y, 0, split_i)\n",
    "dataset_test = custom_dataset(X_test,y_test, 0 ,X_test.shape[0])\n",
    "#dataset_test = custom_dataset(X,y, split_i, X.shape[0] - split_i)\n",
    "#dataset, dataset_test = torch.utils.data.random_split(dataset, [0.98,0.02])\n",
    "train_dl = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dl = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.5650e+01],\n",
       "        [ 3.7420e+02],\n",
       "        [-2.8142e+01],\n",
       "        [ 2.4184e+01],\n",
       "        [-1.8413e+02],\n",
       "        [ 1.2527e+01],\n",
       "        [-1.0289e+01],\n",
       "        [ 1.4973e+02],\n",
       "        [-9.2157e+01],\n",
       "        [-9.6018e+01],\n",
       "        [-6.5280e+01],\n",
       "        [ 4.7821e+01],\n",
       "        [ 7.3338e+01],\n",
       "        [ 7.4025e+01],\n",
       "        [-2.5373e+01],\n",
       "        [ 1.7859e+02],\n",
       "        [-2.2752e+02],\n",
       "        [ 1.7075e+02],\n",
       "        [-9.9035e+01],\n",
       "        [ 1.3884e+02],\n",
       "        [ 2.1542e+02],\n",
       "        [-1.0822e+02],\n",
       "        [ 8.5744e+01],\n",
       "        [ 4.1299e+01],\n",
       "        [-2.5045e+02],\n",
       "        [ 2.0543e+02],\n",
       "        [ 2.9728e+02],\n",
       "        [ 1.1194e+02],\n",
       "        [-1.8255e+02],\n",
       "        [-1.0233e+01],\n",
       "        [-3.3692e+01],\n",
       "        [ 1.3247e+02],\n",
       "        [-8.2365e+01],\n",
       "        [ 7.4973e+01],\n",
       "        [ 1.2076e+02],\n",
       "        [ 1.0953e+02],\n",
       "        [-4.5614e+01],\n",
       "        [ 1.9838e+01],\n",
       "        [ 1.4955e+02],\n",
       "        [-7.9637e+01],\n",
       "        [ 2.0058e+02],\n",
       "        [ 3.2565e+02],\n",
       "        [-1.7169e+02],\n",
       "        [ 1.9918e+01],\n",
       "        [-7.9559e+01],\n",
       "        [ 1.9333e+01],\n",
       "        [-2.5173e+01],\n",
       "        [-3.1797e+02],\n",
       "        [-1.4320e+01],\n",
       "        [ 2.1884e+02],\n",
       "        [-1.9678e+01],\n",
       "        [ 1.1765e+01],\n",
       "        [ 8.8844e+01],\n",
       "        [ 2.8284e+01],\n",
       "        [ 1.5694e+02],\n",
       "        [ 8.0963e+01],\n",
       "        [ 1.1768e+02],\n",
       "        [-3.1114e+01],\n",
       "        [ 6.8983e+01],\n",
       "        [ 4.4422e+01],\n",
       "        [ 1.1054e+02],\n",
       "        [-8.5776e+01],\n",
       "        [ 9.1323e+01],\n",
       "        [ 1.5120e+02],\n",
       "        [ 1.1278e+02],\n",
       "        [ 6.4832e+01],\n",
       "        [ 1.4183e+02],\n",
       "        [ 2.6521e+02],\n",
       "        [-1.1606e+02],\n",
       "        [ 2.2698e+02],\n",
       "        [ 7.6504e+01],\n",
       "        [ 3.2244e+01],\n",
       "        [-2.0120e+02],\n",
       "        [ 2.1300e+02],\n",
       "        [ 2.6187e+02],\n",
       "        [-2.8353e+02],\n",
       "        [-7.2743e+01],\n",
       "        [ 1.3106e+02],\n",
       "        [ 5.6931e+01],\n",
       "        [-6.5680e+01],\n",
       "        [-5.3031e+01],\n",
       "        [-2.5454e+02],\n",
       "        [ 1.5872e+02],\n",
       "        [-5.4283e+01],\n",
       "        [ 1.5616e+01],\n",
       "        [ 2.0090e+02],\n",
       "        [ 6.9505e+01],\n",
       "        [-2.0816e+02],\n",
       "        [ 2.0235e+02],\n",
       "        [-5.2078e+01],\n",
       "        [ 2.8698e+01],\n",
       "        [ 1.0516e+01],\n",
       "        [-6.3410e+01],\n",
       "        [ 1.4490e+02],\n",
       "        [-1.2089e+02],\n",
       "        [-1.4684e+02],\n",
       "        [ 2.3257e+01],\n",
       "        [ 5.4574e+01],\n",
       "        [-1.4989e+02],\n",
       "        [ 1.6973e+01],\n",
       "        [-4.9602e+01],\n",
       "        [-1.2724e+02],\n",
       "        [ 1.7079e+02],\n",
       "        [ 7.2861e+01],\n",
       "        [-3.5013e+01],\n",
       "        [ 4.0049e+01],\n",
       "        [-2.4814e-01],\n",
       "        [ 8.4640e+01],\n",
       "        [-1.1983e+02],\n",
       "        [-2.6729e+01],\n",
       "        [ 1.8440e+02],\n",
       "        [-8.7388e+01],\n",
       "        [-2.7897e+02],\n",
       "        [ 2.4283e+02],\n",
       "        [-1.1224e+02],\n",
       "        [ 1.0279e+01],\n",
       "        [ 2.5213e+01],\n",
       "        [ 4.9395e+01],\n",
       "        [-4.3780e+01],\n",
       "        [ 1.3567e+02],\n",
       "        [-1.0456e+02],\n",
       "        [ 5.8057e+01],\n",
       "        [ 1.5236e+02],\n",
       "        [-1.7012e+02],\n",
       "        [ 1.2973e+02],\n",
       "        [-2.3531e+01],\n",
       "        [ 1.2787e+02],\n",
       "        [ 1.1011e+02]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to complex numbers\n",
    "tt =next(iter(train_dl)) \n",
    "X = tt[0]\n",
    "y = tt[1]\n",
    "\n",
    "#def augment_shift(X,y):\n",
    "X = torch.complex(X[:,0],X[:,1])\n",
    "#print(.shape)\n",
    "#augment 1, multiply each of the vectors with phase\n",
    "\n",
    "\n",
    "max_shift = 100 # number of samples to max_shift\n",
    "sample_length = 10000\n",
    "\n",
    "\n",
    "imag_unit = torch.complex(torch.tensor(0.0),torch.tensor(1.0))\n",
    "sample_shift = (torch.rand(X.shape[0],1,2)*2 - 1)*max_shift\n",
    "phase_shift = (sample_shift/sample_length*2*torch.pi*imag_unit).exp()\n",
    "new_abf = X*(-phase_shift*torch.arange(X.shape[1]).unsqueeze(1))\n",
    "X = torch.stack([torch.real(new_abf),torch.imag(new_abf)], dim=1)\n",
    "y - sample_shift[:,:,0] + sample_shift[:,:,1]\n",
    "#return (X,y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#torch.view_as_complex(abf.permute(1,2,0))\n",
    "#abf.permute(1,2,0).stride(1)\n",
    "\n",
    "#abf.shape\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
