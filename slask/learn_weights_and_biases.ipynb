{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import wandb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33merik-tegler\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eriktegler/phd_studies/Forskning/timeshift_ML/slask/wandb/run-20231204_085537-gmpjk43j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/erik-tegler/timeshift_ML-slask/runs/gmpjk43j' target=\"_blank\">leafy-sponge-2</a></strong> to <a href='https://wandb.ai/erik-tegler/timeshift_ML-slask' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/erik-tegler/timeshift_ML-slask' target=\"_blank\">https://wandb.ai/erik-tegler/timeshift_ML-slask</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/erik-tegler/timeshift_ML-slask/runs/gmpjk43j' target=\"_blank\">https://wandb.ai/erik-tegler/timeshift_ML-slask/runs/gmpjk43j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/erik-tegler/timeshift_ML-slask/runs/gmpjk43j?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x16e814400>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs = 5\n",
    "\n",
    "wandb.init()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16e8fcaf0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Demonstrate that we can display data\n",
    "indx = 2\n",
    "im = test_data[indx][0]\n",
    "im = im.squeeze()\n",
    "plt.imshow(im,cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "NeuralNetwork(\n",
      "  (linear_relu_stack1): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack2): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear_relu_stack1 = nn.Sequential(\n",
    "        nn.Conv2d(1, 8, 3, stride=2),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(8, 16, 3, stride=2),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(16, 32, 3, stride=2),\n",
    "        nn.ReLU(),\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack2 = nn.Sequential(\n",
    "            \n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear_relu_stack1(x)\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack2(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            wandb.log({\"loss\": loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.307638  [    0/60000]\n",
      "loss: 2.300092  [ 6400/60000]\n",
      "loss: 2.291222  [12800/60000]\n",
      "loss: 0.987057  [19200/60000]\n",
      "loss: 0.397507  [25600/60000]\n",
      "loss: 0.306346  [32000/60000]\n",
      "loss: 0.255680  [38400/60000]\n",
      "loss: 0.256674  [44800/60000]\n",
      "loss: 0.257445  [51200/60000]\n",
      "loss: 0.229398  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.1%, Avg loss: 0.231748 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.180239  [    0/60000]\n",
      "loss: 0.128982  [ 6400/60000]\n",
      "loss: 0.102629  [12800/60000]\n",
      "loss: 0.281393  [19200/60000]\n",
      "loss: 0.075211  [25600/60000]\n",
      "loss: 0.089462  [32000/60000]\n",
      "loss: 0.090596  [38400/60000]\n",
      "loss: 0.160517  [44800/60000]\n",
      "loss: 0.208037  [51200/60000]\n",
      "loss: 0.121898  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.1%, Avg loss: 0.124350 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.056557  [    0/60000]\n",
      "loss: 0.124348  [ 6400/60000]\n",
      "loss: 0.071332  [12800/60000]\n",
      "loss: 0.214767  [19200/60000]\n",
      "loss: 0.042347  [25600/60000]\n",
      "loss: 0.049662  [32000/60000]\n",
      "loss: 0.080401  [38400/60000]\n",
      "loss: 0.122264  [44800/60000]\n",
      "loss: 0.175186  [51200/60000]\n",
      "loss: 0.081230  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.095459 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.033644  [    0/60000]\n",
      "loss: 0.112461  [ 6400/60000]\n",
      "loss: 0.092994  [12800/60000]\n",
      "loss: 0.156020  [19200/60000]\n",
      "loss: 0.042579  [25600/60000]\n",
      "loss: 0.048412  [32000/60000]\n",
      "loss: 0.063097  [38400/60000]\n",
      "loss: 0.091381  [44800/60000]\n",
      "loss: 0.170322  [51200/60000]\n",
      "loss: 0.061436  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.086910 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.024771  [    0/60000]\n",
      "loss: 0.104384  [ 6400/60000]\n",
      "loss: 0.097829  [12800/60000]\n",
      "loss: 0.051513  [19200/60000]\n",
      "loss: 0.055733  [25600/60000]\n",
      "loss: 0.024823  [32000/60000]\n",
      "loss: 0.052305  [38400/60000]\n",
      "loss: 0.085788  [44800/60000]\n",
      "loss: 0.148062  [51200/60000]\n",
      "loss: 0.048386  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.089475 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "wandb.watch(model, log_freq=1)\n",
    "loss_fn = nn.CrossEntropyLoss() # What loss function to use for the output of the network\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1) # What method to use for local optimization of the network, currently stochastic gradient descent\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
