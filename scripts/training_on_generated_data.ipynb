{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import scipy.io.wavfile as wav\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torchaudio\n",
    "import glob\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from bisect import bisect_left\n",
    "import scipy as sp\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"../datasets/generated_dataset/\"\n",
    "device = 'cuda' if torch.cuda.is_available() else ('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "dropout = 0.1\n",
    "batch_size = 512\n",
    "fs = 16000\n",
    "\n",
    "\n",
    "f = h5py.File(\"../datasets/generated_dataset/generated_dataset.hdf5\",\"r\")\n",
    "f_test = h5py.File(\"../datasets/generated_dataset/generated_dataset_val.hdf5\",\"r\")\n",
    "\n",
    "X = f['input']\n",
    "y = f['gt']\n",
    "X_test = f_test['input']\n",
    "y_test = f_test['gt']\n",
    "\n",
    "#X = torch.load(os.path.join(data_folder,\"input2.pt\"))\n",
    "#y = torch.load(os.path.join(data_folder,\"gt2.pt\"))\n",
    "#X_test = torch.load(os.path.join(data_folder,\"input.pt\"))\n",
    "#y_test = torch.load(os.path.join(data_folder,\"gt.pt\"))\n",
    "\n",
    "class custom_dataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx],self.y[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "dataset = custom_dataset(X,y)\n",
    "dataset_test = custom_dataset(X_test,y_test)\n",
    "train_dl = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dl = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cnn_output_size_at_factor_1 = 576\n",
    "factor = 2\n",
    "class Block(nn.Module):\n",
    "    def __init__(self,size):\n",
    "        super().__init__()\n",
    "        self.l = nn.Linear(size,size)\n",
    "        self.act = nn.GELU()\n",
    "        #self.ln = nn.LayerNorm(size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.act(self.l(x))\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #self.ln1 = nn.LayerNorm(6250)\n",
    "        #self.ln2 = nn.LayerNorm(2016)\n",
    "        \n",
    "        self.thinker = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            Block(cnn_output_size_at_factor_1*factor),\n",
    "            Block(cnn_output_size_at_factor_1*factor),\n",
    "            Block(cnn_output_size_at_factor_1*factor),\n",
    "        )\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(4,16*factor, 50,stride=5),\n",
    "            nn.GELU(),\n",
    "            nn.Conv1d(16*factor,32*factor, 50,stride=5),\n",
    "            nn.GELU(),\n",
    "            nn.Conv1d(32*factor,48*factor, 30,stride=5),\n",
    "            nn.GELU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        self.compress = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(cnn_output_size_at_factor_1*factor, 10*factor),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(10*factor, 1),\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "        \n",
    "                \n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        \n",
    "        x = self.thinker(x)\n",
    "        return self.compress(x)\n",
    "    \n",
    "model = Classifier().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss()\n",
    "#loss_fn = torch.nn.HuberLoss(delta=10)\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    save_loss_to_file = []\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    \n",
    "    n_batch_before_print = 100\n",
    "    print_loss = 0\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        \n",
    "        # Compute prediction error\n",
    "        X = torch.concatenate([X[:,:,:,0], X[:,:,:,1]], dim=1)\n",
    "        X /= 1e6\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        pred = model(X)\n",
    "        \n",
    "\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print_loss += loss.detach()/n_batch_before_print\n",
    "        if batch % n_batch_before_print == 0 and batch != 0:\n",
    "            loss, current = print_loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            print_loss = 0\n",
    "            save_loss_to_file.append((loss, current))\n",
    "    return save_loss_to_file\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        print_loss = 0\n",
    "        for batch, (X,y) in enumerate(dataloader):\n",
    "            \n",
    "            # Compute prediction error\n",
    "            X = torch.concatenate([X[:,:,:,0], X[:,:,:,1]], dim=1)\n",
    "            X /= 1e6\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            \n",
    "\n",
    "            loss = loss_fn(pred, y)        \n",
    "            print_loss += loss.detach()\n",
    "\n",
    "        loss = print_loss.item()/len(dataloader)\n",
    "        print(f\"Test loss: {loss:>7f}\")\n",
    "        print_loss = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Test loss: 4816.484375\n",
      "loss: 2655.358887  [51200/500000]\n",
      "loss: 2600.833008  [102400/500000]\n",
      "loss: 2568.262207  [153600/500000]\n",
      "loss: 2617.191406  [204800/500000]\n",
      "loss: 2623.901611  [256000/500000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9729/1014952051.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mloss_to_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mloss_to_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m  \u001b[0;31m#   if t < schedule_steps:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m  \u001b[0;31m#       scheduler.step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_9729/3057898660.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_9729/379463351.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthinker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    304\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[0;32m--> 306\u001b[0;31m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    307\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "\n",
    "schedule_steps = 0\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=10)\n",
    "for t in range(epochs):\n",
    "    losses = np.zeros((0,2))\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    #torch.save(model, \"model_musan_epoch_\" + str(t)+ \".pth\")\n",
    "\n",
    "    loss_to_file = test(test_dl, model, loss_fn)\n",
    "    loss_to_file = train(train_dl, model, loss_fn, optimizer)\n",
    " #   if t < schedule_steps:\n",
    " #       scheduler.step()\n",
    "    \n",
    "    #losses = np.concatenate([losses,np.array(loss_to_file\n",
    "    # )])\n",
    "    #np.save(\"losses\", losses)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbba8580cd0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(dataset[0][0][1,:,0]/1e6)\n",
    "#next(iter(train_dl))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
