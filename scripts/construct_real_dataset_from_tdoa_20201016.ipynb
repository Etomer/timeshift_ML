{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_path = \"../datasets/tdoa_20201016/data\"\n",
    "experiment = \"music_0014\"\n",
    "\n",
    "\n",
    "n_audio_files = len(glob(os.path.join(dataset_path,experiment,\"*.wav\")))\n",
    "\n",
    "sounds = []\n",
    "for i in range(n_audio_files):\n",
    "    fs, temp = wavfile.read(os.path.join(dataset_path,experiment,\"Track \" + str(i+1) + \".wav\"))\n",
    "    sounds.append(temp)\n",
    "sounds = np.stack(sounds)\n",
    "\n",
    "#read gt\n",
    "df = pd.read_csv(os.path.join(dataset_path, experiment, \"gt_positions.csv\")) # Note time-column = 0 when audio-recordings started\n",
    "\n",
    "dims = [\"x\",\"y\",\"z\"]\n",
    "time = df[\"time\"]\n",
    "senders = df[[\"speaker\" + \"_\" +dim for dim in dims]].to_numpy()\n",
    "receivers = np.zeros((n_audio_files,3))\n",
    "for i in range(n_audio_files):\n",
    "    for j,dim in enumerate([\"x\",\"y\",\"z\"]):\n",
    "        temp = df[\"mic\" + str(i+1) + \"_\" + dim]\n",
    "        receivers[i,j] = temp[temp.notnull()].median()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#settings\n",
    "downsampling_factor = 6 # going from 96 kHz to 16 kHz which models are trained on\n",
    "chunk_length = 10000\n",
    "max_freq = 2500 #component of fft, NOT in HZ\n",
    "\n",
    "#constants\n",
    "n_chunks = (sounds.shape[1]//downsampling_factor) // (chunk_length)\n",
    "n_mics = sounds.shape[0]\n",
    "n_pairs = n_mics*(n_mics-1)//2\n",
    "speed_of_sound = 343\n",
    "max_diff_meters = chunk_length*speed_of_sound/(2*fs)\n",
    "\n",
    "# divide sound into chunks\n",
    "chunks = sounds[:,::downsampling_factor][:,:n_chunks*chunk_length].reshape(n_mics, n_chunks, chunk_length)\n",
    "chunk_times = np.array([downsampling_factor*chunk_length/fs*i for i in range(n_chunks)])\n",
    "\n",
    "# time sync ground truth to chunks\n",
    "sender_position_at_chunk = np.stack([np.interp(chunk_times,time,senders[:,i]) for i in range(3)]).T\n",
    "\n",
    "# create all pairs\n",
    "pairs = np.zeros(((chunks.shape[0]*(chunks.shape[0]-1))//2, chunks.shape[1], 4 ,max_freq))\n",
    "pairs_gt = np.zeros(((chunks.shape[0]*(chunks.shape[0]-1))//2, chunks.shape[1]))\n",
    "counter = 0\n",
    "for mic1 in range(12):\n",
    "    for mic2 in range(mic1+1,12):\n",
    "        pairs[counter,:,0] = np.real(sp.fft.rfft(chunks[mic1])[:,:max_freq])\n",
    "        pairs[counter,:,1] = np.real(sp.fft.rfft(chunks[mic2])[:,:max_freq])\n",
    "        pairs[counter,:,2] = np.imag(sp.fft.rfft(chunks[mic1])[:,:max_freq])\n",
    "        pairs[counter,:,3] = np.imag(sp.fft.rfft(chunks[mic2])[:,:max_freq])\n",
    "        \n",
    "\n",
    "        pairs_gt[counter] = (np.linalg.norm(sender_position_at_chunk - receivers[mic2],axis=1) - np.linalg.norm(sender_position_at_chunk - receivers[mic1],axis=1))\n",
    "        counter += 1 \n",
    "pairs = pairs.reshape(-1, 4, pairs.shape[3])\n",
    "pairs_gt = pairs_gt.reshape(-1)\n",
    "\n",
    "# filter chunks\n",
    "keep_indx = []\n",
    "for i in range(pairs.shape[0]):\n",
    "    if not np.isnan(pairs[i]).any() and not np.isnan(pairs_gt[i]).any():\n",
    "        keep_indx.append(i)\n",
    "pairs = pairs[keep_indx]\n",
    "pairs_gt = pairs_gt[keep_indx]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store as dataset\n",
    "dataset_path = \"../datasets/music_0014_tdoa_test_data.hdf5\"\n",
    "\n",
    "with h5py.File(dataset_path,\"w\") as hdf5_file:\n",
    "    \n",
    "    X = hdf5_file.create_dataset(\"input\", pairs.shape, dtype=\"f\")\n",
    "    Y = hdf5_file.create_dataset(\"gt\", pairs_gt.shape, dtype=\"f\")\n",
    "\n",
    "\n",
    "    for i in range(pairs.shape[0]):\n",
    "        X[i] = pairs[i]\n",
    "        Y[i] = pairs_gt[i]\n",
    "    \n",
    "    X.attrs.create(\"dataset_type\", \"unpackaged\")\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(dataset_path,\"r\") as hdf5_file:\n",
    "    print(hdf5_file[\"input\"].attrs[\"dataset_type\"] == \"unpackaged\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
